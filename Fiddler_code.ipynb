{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6PG_PkL1iEs",
        "outputId": "4311961d-df49-4e30-bb44-88322af15f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Status   Method  Size    Time  \\\n",
            "0       204      GET     0   540.0   \n",
            "1       200  CONNECT     0   239.0   \n",
            "2       204      GET     0   655.0   \n",
            "3       200  CONNECT     0  1988.0   \n",
            "4       204      GET     0  3417.0   \n",
            "..      ...      ...   ...     ...   \n",
            "628     200  CONNECT     0   100.0   \n",
            "629     200  CONNECT     0   100.0   \n",
            "630     200  CONNECT     0   192.0   \n",
            "631     200  CONNECT     0    86.0   \n",
            "632     200  CONNECT     0    85.0   \n",
            "\n",
            "                                                   URL  \n",
            "0    http://connectivitycheck.gstatic.com/generate_204  \n",
            "1                            http://www.google.com:443  \n",
            "2              http://play.googleapis.com/generate_204  \n",
            "3                            http://www.google.com:443  \n",
            "4    http://connectivitycheck.gstatic.com/generate_204  \n",
            "..                                                 ...  \n",
            "628                  http://play-fe.googleapis.com:443  \n",
            "629                  http://play-fe.googleapis.com:443  \n",
            "630                 http://spclient.wg.spotify.com:443  \n",
            "631                             http://discord.com:443  \n",
            "632                             http://discord.com:443  \n",
            "\n",
            "[633 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv(\"/content/output.csv\")\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output.csv\")  # Replace with your dataset\n",
        "X = data[\"URL\"]  # URL or other relevant feature\n",
        "y = data[\"Status\"]  # Status or classification label\n",
        "\n",
        "# Encode the URLs\n",
        "url_encoder = LabelEncoder()\n",
        "X = url_encoder.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model using Keras\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Calculate input_dim based on the number of unique URLs in your dataset\n",
        "input_dim = len(url_encoder.classes_)\n",
        "\n",
        "# Replace the placeholder values (10000, 32, 1)\n",
        "output_dim = 32  # You can experiment with different values\n",
        "input_length = 1\n",
        "\n",
        "model.add(keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "model.add(keras.layers.LSTM(units=64))\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
        "\n",
        "# To classify real-time traffic, you'll need to capture and preprocess incoming traffic\n",
        "# Then, use the trained model to make predictions on the real-time data\n",
        "\n",
        "# For deployment, consider saving and loading the trained model using model.save() and tf.keras.models.load_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMKRJWJ23tpi",
        "outputId": "d0ea03ac-6cdc-4c6d-e422-16bec31c7899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 3s 43ms/step - loss: -18.8443 - accuracy: 0.0000e+00 - val_loss: -47.3069 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 7ms/step - loss: -93.7121 - accuracy: 0.0000e+00 - val_loss: -162.6553 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: -294.5621 - accuracy: 0.0000e+00 - val_loss: -474.9048 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: -848.1063 - accuracy: 0.0000e+00 - val_loss: -1301.4498 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 7ms/step - loss: -2273.6589 - accuracy: 0.0000e+00 - val_loss: -3290.2988 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 7ms/step - loss: -5456.0151 - accuracy: 0.0000e+00 - val_loss: -7461.4951 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 7ms/step - loss: -11587.0781 - accuracy: 0.0000e+00 - val_loss: -14789.3447 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 7ms/step - loss: -21438.1660 - accuracy: 0.0000e+00 - val_loss: -25598.3027 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 7ms/step - loss: -34815.0859 - accuracy: 0.0000e+00 - val_loss: -39337.9336 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 7ms/step - loss: -50919.9531 - accuracy: 0.0000e+00 - val_loss: -55307.8047 - val_accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -55307.8047 - accuracy: 0.0000e+00\n",
            "Test Loss: -55307.8046875, Test Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output (1).csv\")  # Replace with your dataset\n",
        "X = data[\"URL\"]  # URL or other relevant feature\n",
        "y = data[\"Status\"]  # Status or classification label\n",
        "\n",
        "# Encode the URLs\n",
        "url_encoder = LabelEncoder()\n",
        "X = url_encoder.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model using Keras\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Calculate input_dim based on the number of unique URLs in your dataset\n",
        "input_dim = len(url_encoder.classes_)\n",
        "\n",
        "# Replace the placeholder values (10000, 32, 1)\n",
        "output_dim = 32  # You can experiment with different values\n",
        "input_length = 1\n",
        "\n",
        "model.add(keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "model.add(keras.layers.LSTM(units=64))\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
        "\n",
        "# To classify real-time traffic, you'll need to capture and preprocess incoming traffic\n",
        "# Then, use the trained model to make predictions on the real-time data\n",
        "\n",
        "# For deployment, consider saving and loading the trained model using model.save() and tf.keras.models.load_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db037cf-f449-4dbf-9ce1-a859399630ed",
        "id": "spWNNh_E5ip1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 3s 66ms/step - loss: -6.9751 - accuracy: 0.0000e+00 - val_loss: -18.9544 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: -31.4507 - accuracy: 0.0000e+00 - val_loss: -51.1173 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: -74.0652 - accuracy: 0.0000e+00 - val_loss: -109.4862 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: -153.4544 - accuracy: 0.0000e+00 - val_loss: -220.5431 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: -307.9604 - accuracy: 0.0000e+00 - val_loss: -432.4247 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: -600.5869 - accuracy: 0.0000e+00 - val_loss: -826.2869 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: -1136.9293 - accuracy: 0.0000e+00 - val_loss: -1535.8280 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: -2086.1182 - accuracy: 0.0000e+00 - val_loss: -2756.6514 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: -3662.6755 - accuracy: 0.0000e+00 - val_loss: -4715.3042 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: -6137.4639 - accuracy: 0.0000e+00 - val_loss: -7649.8784 - val_accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -7649.8784 - accuracy: 0.0000e+00\n",
            "Test Loss: -7649.87841796875, Test Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output (2).csv\")  # Replace with your dataset\n",
        "X = data[\"URL\"]  # URL or other relevant feature\n",
        "y = data[\"Status\"]  # Status or classification label\n",
        "\n",
        "# Encode the URLs\n",
        "url_encoder = LabelEncoder()\n",
        "X = url_encoder.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model using Keras\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Calculate input_dim based on the number of unique URLs in your dataset\n",
        "input_dim = len(url_encoder.classes_)\n",
        "\n",
        "# Replace the placeholder values (10000, 32, 1)\n",
        "output_dim = 32  # You can experiment with different values\n",
        "input_length = 1\n",
        "\n",
        "model.add(keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "model.add(keras.layers.LSTM(units=64))\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
        "\n",
        "# To classify real-time traffic, you'll need to capture and preprocess incoming traffic\n",
        "# Then, use the trained model to make predictions on the real-time data\n",
        "\n",
        "# For deployment, consider saving and loading the trained model using model.save() and tf.keras.models.load_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c4d8cb-42c0-403c-e76f-ceed354114ce",
        "id": "3fLhnG7q52H5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 4s 118ms/step - loss: -3.6345 - accuracy: 0.0000e+00 - val_loss: -11.1759 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 10ms/step - loss: -16.5691 - accuracy: 0.0000e+00 - val_loss: -26.2717 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 14ms/step - loss: -33.6835 - accuracy: 0.0000e+00 - val_loss: -46.6602 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 15ms/step - loss: -57.2874 - accuracy: 0.0000e+00 - val_loss: -75.4556 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 13ms/step - loss: -91.0944 - accuracy: 0.0000e+00 - val_loss: -117.1618 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 14ms/step - loss: -140.2258 - accuracy: 0.0000e+00 - val_loss: -178.3086 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 11ms/step - loss: -213.4361 - accuracy: 0.0000e+00 - val_loss: -268.7293 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 11ms/step - loss: -321.3492 - accuracy: 0.0000e+00 - val_loss: -401.6420 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 11ms/step - loss: -479.0660 - accuracy: 0.0000e+00 - val_loss: -595.4221 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 12ms/step - loss: -709.3047 - accuracy: 0.0000e+00 - val_loss: -874.2764 - val_accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 11ms/step - loss: -874.2764 - accuracy: 0.0000e+00\n",
            "Test Loss: -874.2764282226562, Test Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output.csv\")  # Replace with your dataset\n",
        "X = data[\"URL\"]  # URL or other relevant feature\n",
        "y = data[\"Status\"]  # Status or classification label\n",
        "\n",
        "# Encode the URLs\n",
        "url_encoder = LabelEncoder()\n",
        "X_encoded = url_encoder.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train.reshape(-1, 1))\n",
        "X_test = scaler.transform(X_test.reshape(-1, 1))\n",
        "\n",
        "# Define a simple neural network model using Keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(64, activation='relu', input_shape=(1,)))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred_classes)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNWN8kLCMEoA",
        "outputId": "ec6c5149-99dd-411c-9ba2-d1f7a552e981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 1s 13ms/step - loss: -79.3187 - accuracy: 0.0000e+00 - val_loss: -142.8198 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: -213.9202 - accuracy: 0.0000e+00 - val_loss: -310.9822 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: -436.6216 - accuracy: 0.0000e+00 - val_loss: -609.5014 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: -820.0753 - accuracy: 0.0000e+00 - val_loss: -1093.9899 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: -1424.7318 - accuracy: 0.0000e+00 - val_loss: -1842.6656 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: -2330.0242 - accuracy: 0.0000e+00 - val_loss: -2952.7864 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: -3651.1104 - accuracy: 0.0000e+00 - val_loss: -4524.2646 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: -5503.2241 - accuracy: 0.0000e+00 - val_loss: -6677.9551 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: -7980.9814 - accuracy: 0.0000e+00 - val_loss: -9541.9805 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: -11212.6006 - accuracy: 0.0000e+00 - val_loss: -13204.2236 - val_accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Test Accuracy: 0.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "         200       0.00      0.00      0.00      95.0\n",
            "         204       0.00      0.00      0.00      31.0\n",
            "         401       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00     127.0\n",
            "   macro avg       0.00      0.00      0.00     127.0\n",
            "weighted avg       0.00      0.00      0.00     127.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/output.csv\")\n",
        "# Display the first few rows of your dataset\n",
        "print(data.head())\n",
        "\n",
        "# List all the column names\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI8G5wAMRd2B",
        "outputId": "c9d8bc62-d8ed-4d9f-d088-b901d0eb6d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Status   Method  Size    Time  \\\n",
            "0     204      GET     0   540.0   \n",
            "1     200  CONNECT     0   239.0   \n",
            "2     204      GET     0   655.0   \n",
            "3     200  CONNECT     0  1988.0   \n",
            "4     204      GET     0  3417.0   \n",
            "\n",
            "                                                 URL  \n",
            "0  http://connectivitycheck.gstatic.com/generate_204  \n",
            "1                          http://www.google.com:443  \n",
            "2            http://play.googleapis.com/generate_204  \n",
            "3                          http://www.google.com:443  \n",
            "4  http://connectivitycheck.gstatic.com/generate_204  \n",
            "Index(['Status', 'Method', 'Size', 'Time', 'URL'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output.csv\")  # Replace with your dataset path\n",
        "\n",
        "# Extract features\n",
        "features = data[['Size', 'Time']]\n",
        "\n",
        "# Label data\n",
        "labels = data['Status']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model using Keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(64, activation='relu', input_shape=(features.shape[1],)))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred_classes)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BVrCQfSVFBe",
        "outputId": "a45ba889-5754-4f5c-a1a0-b747ff3d6418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 1s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Test Accuracy: 0.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       0.0\n",
            "         200       0.00      0.00      0.00      95.0\n",
            "         204       0.00      0.00      0.00      31.0\n",
            "         401       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00     127.0\n",
            "   macro avg       0.00      0.00      0.00     127.0\n",
            "weighted avg       0.00      0.00      0.00     127.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOv9j-TE3T68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output (1).csv\")  # Replace with your dataset path\n",
        "\n",
        "# Extract features\n",
        "features = data[['Size', 'Time']]\n",
        "\n",
        "# Label data\n",
        "labels = data['Status']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model using Keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(64, activation='relu', input_shape=(features.shape[1],)))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred_classes)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1381d638-a776-45f9-f320-d5b7e801e3be",
        "id": "_Soopp3w3UPj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 28ms/step - loss: 1918.4454 - accuracy: 0.0000e+00 - val_loss: -1756.6106 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: -3768.1184 - accuracy: 0.0000e+00 - val_loss: -7238.1064 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: -9245.1201 - accuracy: 0.0000e+00 - val_loss: -12929.4385 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: -14762.9082 - accuracy: 0.0000e+00 - val_loss: -19165.4395 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: -21265.6875 - accuracy: 0.0000e+00 - val_loss: -26905.3066 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: -29542.4395 - accuracy: 0.0000e+00 - val_loss: -37333.9727 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: -40888.0586 - accuracy: 0.0000e+00 - val_loss: -52329.2930 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: -57870.1680 - accuracy: 0.0000e+00 - val_loss: -72804.9453 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: -80475.6797 - accuracy: 0.0000e+00 - val_loss: -99861.7812 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: -109418.9453 - accuracy: 0.0000e+00 - val_loss: -136108.1094 - val_accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Test Accuracy: 0.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "         200       0.00      0.00      0.00      68.0\n",
            "         204       0.00      0.00      0.00       7.0\n",
            "\n",
            "    accuracy                           0.00      75.0\n",
            "   macro avg       0.00      0.00      0.00      75.0\n",
            "weighted avg       0.00      0.00      0.00      75.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output (2).csv\")  # Replace with your dataset path\n",
        "\n",
        "# Extract features\n",
        "features = data[['Size', 'Time']]\n",
        "\n",
        "# Label data\n",
        "labels = data['Status']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model using Keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(64, activation='relu', input_shape=(features.shape[1],)))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred_classes)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283f6498-6c3b-4033-e4d9-fd9c50a81e9e",
        "id": "L0YgrObX3nCi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 41ms/step - loss: nan - accuracy: 0.0058 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.0058 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0058 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0058 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0058 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0058 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0058 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0058 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0058 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0058 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Test Accuracy: 0.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       0.0\n",
            "         100       0.00      0.00      0.00       1.0\n",
            "         200       0.00      0.00      0.00      40.0\n",
            "         204       0.00      0.00      0.00       3.0\n",
            "\n",
            "    accuracy                           0.00      44.0\n",
            "   macro avg       0.00      0.00      0.00      44.0\n",
            "weighted avg       0.00      0.00      0.00      44.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output.csv\")  # Replace with your dataset path\n",
        "\n",
        "# Extract features\n",
        "features = data[['Time', 'URL']]\n",
        "\n",
        "# Label data\n",
        "labels = data['Status']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model using Keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(input_dim=10000, output_dim=32, input_length=100))  # Example embedding layer\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred_classes)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "HKbmzmtFFQxF",
        "outputId": "24943d2f-7ebd-4d99-c88a-5589bfbbd169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7b501404f2cc>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output.csv\")  # Replace with your dataset path\n",
        "\n",
        "# Extract features\n",
        "# Assuming \"URL\" represents URLs and we want to extract the length of the URL as a feature\n",
        "data['URL_Length'] = data['URL'].apply(lambda x: len(x))\n",
        "features = data[['Time', 'URL_Length']]\n",
        "\n",
        "# Label data\n",
        "labels = data['Status']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model using Keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(64, activation='relu', input_shape=(features.shape[1],)))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred_classes)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epUOrH9ZF84S",
        "outputId": "0827502e-8846-487b-bd76-8524c471b069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Test Accuracy: 0.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       0.0\n",
            "         200       0.00      0.00      0.00      95.0\n",
            "         204       0.00      0.00      0.00      31.0\n",
            "         401       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00     127.0\n",
            "   macro avg       0.00      0.00      0.00     127.0\n",
            "weighted avg       0.00      0.00      0.00     127.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output.csv\")  # Replace with your dataset path\n",
        "\n",
        "# Drop the 'Size' column\n",
        "data = data.drop(columns=['Size'])\n",
        "\n",
        "# Extract features\n",
        "# Assuming \"URL\" represents URLs and we want to extract the length of the URL as a feature\n",
        "data['URL_Length'] = data['URL'].apply(lambda x: len(x))\n",
        "features = data[['Time', 'URL_Length']]\n",
        "\n",
        "# Label data\n",
        "labels = data['Status']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model using Keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(64, activation='relu', input_shape=(features.shape[1],)))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred_classes)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQXh8e2vHdRz",
        "outputId": "1326627d-1e81-4569-d2c5-392d2f5c8c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 1s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Test Accuracy: 0.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       0.0\n",
            "         200       0.00      0.00      0.00      95.0\n",
            "         204       0.00      0.00      0.00      31.0\n",
            "         401       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00     127.0\n",
            "   macro avg       0.00      0.00      0.00     127.0\n",
            "weighted avg       0.00      0.00      0.00     127.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess your labeled network traffic data using Pandas\n",
        "data = pd.read_csv(\"/content/output.csv\")  # Replace with your dataset path\n",
        "\n",
        "# Extract the domain from the URL\n",
        "data['Domain'] = data['URL'].apply(lambda url: url.split('/')[2] if '/' in url else url)\n",
        "\n",
        "# Group the data by domain and sum the time spent\n",
        "domain_time = data.groupby('Domain')['Time'].sum().reset_index()\n",
        "\n",
        "# Find the domain with the maximum time spent\n",
        "most_used_domain = domain_time.loc[domain_time['Time'].idxmax()]['Domain']\n",
        "\n",
        "print(f\"The most used domain is: {most_used_domain}\")\n",
        "\n",
        "# You can now compare the times spent on different domains to see which one was used more.\n",
        "# If you need further analysis or modeling based on this data, you can integrate it into your existing code.\n",
        "\n",
        "# Note: Make sure to adapt this code to your specific dataset and requirements.\n"
      ],
      "metadata": {
        "id": "PA4etMscSS9q",
        "outputId": "d6d9a4a2-2590-4e7b-f3cc-400ac8b3a323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most used domain is: youtubei.googleapis.com:443\n"
          ]
        }
      ]
    }
  ]
}